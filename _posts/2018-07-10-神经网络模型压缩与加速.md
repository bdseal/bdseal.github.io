---
layout:     post
title:      神经网络模型压缩与加速
date:       2018-07-10
author:     Will Hsia
header-img: img/post-bg-re-vs-ng2.jpg
catalog: true
tags:
    - 模型压缩与加速
---
# 模型压缩与加速
可以参考博文：https://blog.csdn.net/lijiancheng0614/article/details/79478792
我目前用的比较多的部分是，
(1)	改变网络结构-使用特定结构如ShuffleNet, MobileNet, EPSNet等，核心其实就是将常规卷积分解变成Depthwise Separable Convolution，这种结构可以通过im2col + GEMM，将问题转化为矩阵乘法后使用矩阵运算库减少计算量的同时，也与硬件工作原理一致；
(2)	多GPU并行，多线程读取训练数据；
(3)	应用一些工具如horovod。
# horovod相关----分布式训练与硬件潜力
Horovod是Uber发布的标准分布式 TensorFlow 技术。
随着数据集增大和模型复杂度的增加，某些训练时间很长，所以需要分布式的训练方法，tensorflow也公布了如何用tf完成分布式训练。但从下图可以看出，标准方法很难释放出硬件的全部潜能，在128GPU时几乎浪费了一般的计算潜能。所以大规模训练时需要新的方法去充分利用GPU资源。
 
对这个问题的研究比较有影响力的有三篇工作，按时间前后列举如下：
(1)	Facebook 的一小时训练 ImageNet 论文Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour，介绍了使用 256 块 GPU 进行 ResNet-50 网络「数据并行」训练的方法；
(2)	百度发表了研究《Bringing HPC Techniques to Deep Learning》（参见百度将 HPC 引入深度学习：高效实现模型的大规模扩展），提出使用不同的算法来平均梯度，并让这些梯度在所有节点之间交流，这被称为 ring-allreduce；
(3)	Horovod
